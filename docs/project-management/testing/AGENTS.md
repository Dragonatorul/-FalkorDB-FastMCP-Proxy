# Project Management Testing - AI Instructions

## Documentation Hierarchy
- **AGENTS.md** (This file): AI-specific testing documentation process
- **Test result files**: Authentication test results and validation reports

## AI Context for Testing Section
- **AUTHENTICATION_TEST_RESULTS.md**: Claude Desktop Bearer token validation results
- **Test artifacts**: Validation evidence and compatibility confirmation

## AI Maintenance Process
1. **Read this AGENTS.md**: Before any testing documentation work
2. **Update test results**: Add new validation reports after testing sessions
3. **Maintain evidence**: Keep test artifacts current with implementation
4. **Document outcomes**: Record both successful and failed test scenarios
5. **Cross-reference**: Link test results to related implementation changes

## Testing Context (AI Reference)
- **Authentication Tests**: Claude Desktop Bearer token support validated
- **Integration Tests**: End-to-end MCP tool functionality confirmed
- **Compatibility**: Claude Desktop MCP server configuration working
- **Evidence**: Documented proof of working integration

## AI Update Triggers
- New authentication methods tested (update authentication results)
- Integration testing completed (add new test reports)
- Compatibility issues discovered (document failure scenarios)
- Performance testing conducted (add performance reports)

## Content Formatting (AI Guidelines)
- **Evidence-Based**: Include concrete test results and validation data
- **Reproducible**: Document test procedures for future validation
- **Clear Outcomes**: Specify pass/fail status and evidence
- **Historical Record**: Maintain test history for regression analysis

---

> **AI Note**: Testing documentation provides validation evidence for implementation decisions.